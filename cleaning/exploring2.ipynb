{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f303fbb4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b769221d",
   "metadata": {},
   "source": [
    "# Attemp number 2\n",
    "This attemp includes findings from my previous attemp, bringing them together to form a more refined approach at producing a fully cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed559ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppID                                int64\n",
      "Name                                object\n",
      "Release date                datetime64[ns]\n",
      "Estimated owners                    object\n",
      "Required age                         int64\n",
      "Price                              float64\n",
      "User score                           int64\n",
      "Positive                             int64\n",
      "Negative                             int64\n",
      "Recommendations                      int64\n",
      "Average playtime forever             int64\n",
      "Developers                          object\n",
      "Publishers                          object\n",
      "Categories                          object\n",
      "Genres                              object\n",
      "Tags                                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "script_path = Path.cwd()\n",
    "data_path_cleaned = script_path.parent / \"data\" / \"games_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path_cleaned, encoding='utf-8')\n",
    "\n",
    "# Dtatype conversion\n",
    "df['Release date'] = pd.to_datetime(df['Release date'], errors='coerce')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880d1a8",
   "metadata": {},
   "source": [
    "## Estimated average owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb55c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estimated owners  Estimated average owners\n",
      "0        0 - 20000                     10000\n",
      "1        0 - 20000                     10000\n",
      "2        0 - 20000                     10000\n",
      "3        0 - 20000                     10000\n",
      "4        0 - 20000                     10000\n",
      "5   50000 - 100000                     75000\n",
      "6        0 - 20000                     10000\n",
      "7        0 - 20000                     10000\n",
      "8        0 - 20000                     10000\n",
      "9   50000 - 100000                     75000\n"
     ]
    }
   ],
   "source": [
    "# Split 'Estimated owners' into two columns and calculate the average\n",
    "owners_clean = df['Estimated owners'].str.replace(' ', '', regex=False)\n",
    "\n",
    "owners_split = owners_clean.str.split('-', expand=True)\n",
    "\n",
    "owners_split[0] = pd.to_numeric(owners_split[0], errors='coerce')\n",
    "owners_split[1] = pd.to_numeric(owners_split[1], errors='coerce')\n",
    "\n",
    "df['Estimated average owners'] = (owners_split[0] + owners_split[1]) / 2\n",
    "df['Estimated average owners'] = df['Estimated average owners'].astype('Int64')\n",
    "\n",
    "print(df[['Estimated owners', 'Estimated average owners']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922c5bc",
   "metadata": {},
   "source": [
    "## Reranging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d49072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2655, 27)\n"
     ]
    }
   ],
   "source": [
    "# Adding new column for lowercase names\n",
    "df['Name_lowercase'] = df['Name'].str.lower().str.strip()\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df[df['Name_lowercase'].duplicated(keep=False)]\n",
    "print(duplicates.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2c74f",
   "metadata": {},
   "source": [
    "### Positive ratio\n",
    "As we move beyond simple ratios, using only the share of positive reviews can be misleading since it ignores how many reviews support that score. A game with 9 out of 10 positives looks the same as one with 9,000 out of 10,000, even though the latter is far more reliable.\n",
    "\n",
    "The `Bayesian average` fixes this by combining each game’s observed ratio with a prior mean, weighted by how much evidence we have. With few reviews, the score stays near the prior; as reviews grow, it converges to the game’s own ratio. This gives a stable and interpretable quality estimate.\n",
    "\n",
    "Let $\\bar{x}$ be the game’s observed positive ratio, $n$ the number of reviews, $\\mu$ the prior mean (e.g., the global average across all games), and $m$ the prior strength (how many “virtual reviews” the prior contributes). The Bayesian score is:\n",
    "$$\n",
    "\\text{Bayesian Score} \\;=\\; \\frac{\\bar{x}\\,n + \\mu\\,m}{n + m}\n",
    "$$\n",
    "Equivalently, with a Beta prior $\\mathrm{Beta}(\\alpha,\\beta)$ where $\\alpha=m\\mu$ and $\\beta=m(1-\\mu)$ and observed positives $x$ out of $n$:\n",
    "$$\n",
    "\\text{Bayesian Score} \\;=\\; \\frac{x+\\alpha}{n+\\alpha+\\beta}\n",
    "$$\n",
    "**Notes**\n",
    "- Choose $\\mu$ as the global positive rate, or a fixed value like $0.7$ if you want a stable baseline.\n",
    "- Choose $m$ in the range 50–200 for Steam-like data. Larger $m$ pulls small-sample games more strongly toward $\\mu$.\n",
    "- Keep the raw ratio separately for display; use the Bayesian score for ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2655, 27)\n",
      "Mean: 880.2117054875641\n",
      "Median: 5.0\n",
      "Min: 0\n",
      "Max: 6531097\n",
      "Quantiles: 0.25        0.0\n",
      "0.50        5.0\n",
      "0.75       39.0\n",
      "0.90      293.0\n",
      "0.99    11618.0\n",
      "Name: n_reviews, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Bayesian average\n",
    "df[\"n_reviews\"] = df[\"Positive\"] + df[\"Negative\"]\n",
    "df[\"positive ratio\"] = df[\"Positive\"] / df[\"n_reviews\"].replace(0, np.nan)\n",
    "\n",
    "print(\"Mean:\", df[\"n_reviews\"].mean())\n",
    "print(\"Median:\", df[\"n_reviews\"].median())\n",
    "print(\"Min:\", df[\"n_reviews\"].min())\n",
    "print(\"Max:\", df[\"n_reviews\"].max())\n",
    "print(\"Quantiles:\", df[\"n_reviews\"].quantile([0.25,0.5,0.75,0.9,0.99]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84698ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global mean for prior\n",
    "mu = df[\"Positive\"].sum() / df[\"n_reviews\"].sum()\n",
    "\n",
    "def bayesian_score(pos_ratio, n, mu, m):\n",
    "    return ((pos_ratio * n + mu * m) / (n + m)).fillna(mu)\n",
    "\n",
    "# Compute for different m values\n",
    "for m in [50,100,150,200]:\n",
    "    df[f\"bayes_m{m}\"] = bayesian_score(df[\"positive_ratio\"], df[\"n_reviews\"], mu, m)\n",
    "\n",
    "# Filter small samples\n",
    "df_filtered = df[df[\"n_reviews\"] >= 20].copy()\n",
    "\n",
    "# Show top 10 for each m\n",
    "for m in [50,100,150,200]:\n",
    "    print(f\"\\nTop 10 games by Bayesian average (m={m})\")\n",
    "    print(\n",
    "        df_filtered.sort_values(\"n_reviews\", ascending=False)\n",
    "        [[\"n_reviews\",\"Positive\", \"Negative\", \"positive_ratio\", f\"bayes_m{m}\"]]\n",
    "        .head(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sorted = df.sort_values(\n",
    "    by=['Estimated average owners', 'Positive ratio', 'Release date'],\n",
    "    ascending=[False, False, False]\n",
    ")\n",
    "\n",
    "print(df_sorted[['Estimated average owners','Positive ratio','Release date']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c155f",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d79152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppID                           0\n",
      "Name                            6\n",
      "Release date                  131\n",
      "Estimated owners                0\n",
      "Required age                    0\n",
      "Price                           0\n",
      "User score                      0\n",
      "Positive                        0\n",
      "Negative                        0\n",
      "Recommendations                 0\n",
      "Average playtime forever        0\n",
      "Developers                   6475\n",
      "Publishers                   6778\n",
      "Categories                   7566\n",
      "Genres                       6440\n",
      "Tags                        37423\n",
      "Estimated average owners        0\n",
      "Name_lowercase                  6\n",
      "Positive ratio              37588\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initial exploration of missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766506d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developers: 16 rows can be filled from duplicates.\n",
      "Publishers: 26 rows can be filled from duplicates.\n",
      "Categories: 31 rows can be filled from duplicates.\n",
      "Genres: 13 rows can be filled from duplicates.\n",
      "Tags: 595 rows can be filled from duplicates.\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in major columns that can be found in duplicates\n",
    "columns_to_check = ['Developers', 'Publishers', 'Categories', 'Genres', 'Tags']\n",
    "\n",
    "for col in columns_to_check:\n",
    "    missing_rows = df[df[col].isnull()]\n",
    "    \n",
    "    can_be_filled = missing_rows['Name_lowercase'].isin(\n",
    "        df[~df[col].isnull()]['Name_lowercase']\n",
    "    )\n",
    "    \n",
    "    fillable_rows = missing_rows[can_be_filled]\n",
    "    \n",
    "    print(f\"{col}: {len(fillable_rows)} rows can be filled from duplicates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd65ff",
   "metadata": {},
   "source": [
    "\n",
    "To fill the datas across duplicated game entries, I grouped rows by `Name_lowercase` and updated using `.update` with `.ffill` and `.bfill` to propagate only missing values within each group. This way, no matter which duplicate held the information, all rows for the same game now share the filled values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd379a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values from the duplicates\n",
    "cols_to_fill = ['Developers', 'Publishers', 'Categories', 'Genres', 'Tags']\n",
    "\n",
    "for col in cols_to_fill:\n",
    "    df.update(df.groupby('Name_lowercase')[col].ffill())\n",
    "    df.update(df.groupby('Name_lowercase')[col].bfill())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff37f91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developers: 0 rows can be filled from duplicates.\n",
      "Publishers: 0 rows can be filled from duplicates.\n",
      "Categories: 3 rows can be filled from duplicates.\n",
      "Genres: 2 rows can be filled from duplicates.\n",
      "Tags: 0 rows can be filled from duplicates.\n"
     ]
    }
   ],
   "source": [
    "# Double checking the missing values after filling\n",
    "cols_to_check = ['Developers', 'Publishers', 'Categories', 'Genres', 'Tags']\n",
    "\n",
    "for col in cols_to_check:\n",
    "    missing_rows = df[df[col].isnull()]\n",
    "    \n",
    "    can_be_filled = missing_rows['Name_lowercase'].isin(\n",
    "        df[~df[col].isnull()]['Name_lowercase']\n",
    "    )\n",
    "    \n",
    "    fillable_rows = missing_rows[can_be_filled]\n",
    "    \n",
    "    print(f\"{col}: {len(fillable_rows)} rows can be filled from duplicates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b55d53",
   "metadata": {},
   "source": [
    "After filling missing data within duplicate groups, 5 rows are still empty, althought is being detected as the duplicate contains the much needed information, but my .update approach does not seem to work for this specific situations.\n",
    "\n",
    "This may be because of 1. small differences in how the groups were formed or 2. because the update step did not replace the missing values.  \n",
    "Since the number is small, the next step is to check these rows directly or combine the duplicates into a single row per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e4e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppID                           0\n",
      "Name                            6\n",
      "Release date                  131\n",
      "Estimated owners                0\n",
      "Required age                    0\n",
      "Price                           0\n",
      "User score                      0\n",
      "Positive                        0\n",
      "Negative                        0\n",
      "Recommendations                 0\n",
      "Average playtime forever        0\n",
      "Developers                   6459\n",
      "Publishers                   6752\n",
      "Categories                   7538\n",
      "Genres                       6429\n",
      "Tags                        36828\n",
      "Estimated average owners        0\n",
      "Name_lowercase                  6\n",
      "Positive ratio              37588\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d2cfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppID                       0\n",
      "Name                        0\n",
      "Release date                0\n",
      "Estimated owners            0\n",
      "Required age                0\n",
      "Price                       0\n",
      "User score                  0\n",
      "Positive                    0\n",
      "Negative                    0\n",
      "Recommendations             0\n",
      "Average playtime forever    0\n",
      "Developers                  0\n",
      "Publishers                  0\n",
      "Categories                  0\n",
      "Genres                      0\n",
      "Tags                        0\n",
      "Estimated average owners    0\n",
      "Name_lowercase              0\n",
      "Positive ratio              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Only 6 rows still have missing values, therefore dropping them might be the better option. \n",
    "# By dropping these rows, we should also be dropping the rows with missing values in Name_lowercase\n",
    "df = df.dropna(subset=['Name'])\n",
    "\n",
    "#filling remaining string columns with 'Unknown'\n",
    "df['Release date'] = df['Release date'].fillna('Unknown')\n",
    "df['Developers'] = df['Developers'].fillna('Unknown')\n",
    "df['Publishers'] = df['Publishers'].fillna('Unknown')\n",
    "df['Categories'] = df['Categories'].fillna('Unknown')\n",
    "df['Genres'] = df['Genres'].fillna('Unknown')\n",
    "df['Tags'] = df['Tags'].fillna('Unknown')\n",
    "\n",
    "# Filling remaining numeric columns with 0\n",
    "df['Estimated average owners'] = df['Estimated average owners'].fillna(0)\n",
    "df['Positive ratio'] = df['Positive ratio'].fillna(0)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838f4e6",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b949129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned\n"
     ]
    }
   ],
   "source": [
    "# Sorting by the priorities\n",
    "df_sorted = df.sort_values(\n",
    "    by=['Estimated average owners', 'Positive ratio', 'Release date'],\n",
    "    ascending=[False, False, False]\n",
    ")\n",
    "\n",
    "# Keeping the first duplicate as its being sorted already\n",
    "df_drop = df_sorted.drop_duplicates('Name_lowercase', keep='first')\n",
    "\n",
    "data_path_final = script_path.parent / \"data\" / \"games_final.csv\"\n",
    "df_drop.to_csv(data_path_final, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df24294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 19)\n"
     ]
    }
   ],
   "source": [
    "# Double checking the duplicates in the final cleaned file\n",
    "df2 = pd.read_csv(data_path_final, encoding='utf-8')\n",
    "\n",
    "duplicates2 = df2[df2['Name_lowercase'].duplicated(keep=False)]\n",
    "print(duplicates2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
